# -*- coding: utf-8 -*-
"""Q/A Generation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tCWZlDgwh6xrkkV8P5lun20U5XXkT04T
"""

!pip install --quiet flashtext==2.7
!pip install git+https://github.com/boudinfl/pke.git

!pip install --upgrade pip

!sudo pip install --quiet transformers==4.8.1
!sudo pip install --quiet sentencepiece==0.1.95
!sudo pip install --quiet textwrap3==0.9.2
!sudo pip install --quiet gradio==3.0.20

!pip install --quiet strsim==0.0.3
!pip install --quiet sense2vec==2.0.0

# Commented out IPython magic to ensure Python compatibility.
!pip install --quiet ipython-autotime
# %load_ext autotime

!pip install --quiet sentence-transformers==2.2.2

from textwrap3 import wrap



text="""Java is a widely-used and versatile programming language that was first released by Sun Microsystems in 1995. It has since become a fundamental technology in software development and remains popular due to its platform independence and a strong ecosystem of libraries and tools.

One of Java's key features is its "Write Once, Run Anywhere" (WORA) capability, which is made possible by the Java Virtual Machine (JVM). Java source code is compiled into bytecode, which can run on any system with a compatible JVM. This portability has made Java a dominant player in web, mobile, and enterprise applications.

Java is an object-oriented language, meaning that it relies on the concept of objects, which are instances of classes. This approach promotes code reusability, maintainability, and a more structured development process. Java also incorporates strong typing, which helps catch errors during compilation, enhancing code reliability.

Java provides an extensive standard library that covers a wide range of functionalities, including data structures, network communication, and file handling. It also supports multithreading, allowing developers to create concurrent, efficient applications.

Java's popularity extends to Android app development, as Android apps are predominantly written in Java. This positions Java as a critical language for mobile application development, alongside other platforms like iOS with Swift and Objective-C.

Furthermore, the Java community is vast and active, offering an abundance of resources, forums, and documentation to support developers. Tools like Eclipse, IntelliJ IDEA, and NetBeans provide comprehensive integrated development environments for Java programmers.

Overall, Java remains a solid choice for developers seeking a versatile, robust, and widely-adopted programming language for a variety of applications, from web services to mobile apps to large-scale enterprise systems. Its enduring relevance in the software development landscape showcases its durability and adaptability in a rapidly evolving industry."""

for wrp in wrap(text, 150):
  print (wrp)
print ("\n")

import torch
from transformers import T5ForConditionalGeneration,T5Tokenizer
summary_model = T5ForConditionalGeneration.from_pretrained('t5-base')
summary_tokenizer = T5Tokenizer.from_pretrained('t5-base')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
summary_model = summary_model.to(device)

import random
import numpy as np

def set_seed(seed: int):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

set_seed(42)

import nltk
nltk.download('punkt')
nltk.download('brown')
nltk.download('wordnet')
from nltk.corpus import wordnet as wn
from nltk.tokenize import sent_tokenize

def postprocesstext (content):
  final=""
  for sent in sent_tokenize(content):
    sent = sent.capitalize()
    final = final +" "+sent
  return final


def summarizer(text,model,tokenizer):
  text = text.strip().replace("\n"," ")
  text = "summarize: "+text
  # print (text)
  max_len = 512
  encoding = tokenizer.encode_plus(text,max_length=max_len, pad_to_max_length=False,truncation=True, return_tensors="pt").to(device)

  input_ids, attention_mask = encoding["input_ids"], encoding["attention_mask"]

  outs = model.generate(input_ids=input_ids,attention_mask=attention_mask,early_stopping=True,num_beams=3,
                                  num_return_sequences=1,no_repeat_ngram_size=2,min_length = 75,max_length=300)


  dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]
  summary = dec[0]
  summary = postprocesstext(summary)
  summary= summary.strip()

  return summary


summarized_text = summarizer(text,summary_model,summary_tokenizer)


print ("\noriginal Text >>")
for wrp in wrap(text, 150):
  print (wrp)
print ("\n")
print ("Summarized Text >>")
for wrp in wrap(summarized_text, 150):
  print (wrp)
print ("\n")

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
import string
import pke
import traceback

def get_nouns_multipartite(content):
    out=[]
    try:
        extractor = pke.unsupervised.MultipartiteRank()
        extractor.load_document(input=content,language='en')
        #    not contain punctuation marks or stopwords as candidates.
        pos = {'PROPN','NOUN'}
        #pos = {'PROPN','NOUN'}
        stoplist = list(string.punctuation)
        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']
        stoplist += stopwords.words('english')
        # extractor.candidate_selection(pos=pos, stoplist=stoplist)
        extractor.candidate_selection(pos=pos)
        # 4. build the Multipartite graph and rank candidates using random walk,
        #    alpha controls the weight adjustment mechanism, see TopicRank for
        #    threshold/method parameters.
        extractor.candidate_weighting(alpha=1.1,
                                      threshold=0.75,
                                      method='average')
        keyphrases = extractor.get_n_best(n=15)


        for val in keyphrases:
            out.append(val[0])
    except:
        out = []
        traceback.print_exc()

    return out

from flashtext import KeywordProcessor


def get_keywords(originaltext,summarytext):
  keywords = get_nouns_multipartite(originaltext)
  print ("keywords unsummarized: ",keywords)
  keyword_processor = KeywordProcessor()
  for keyword in keywords:
    keyword_processor.add_keyword(keyword)

  keywords_found = keyword_processor.extract_keywords(summarytext)
  keywords_found = list(set(keywords_found))
  print ("keywords_found in summarized: ",keywords_found)

  important_keywords =[]
  for keyword in keywords:
    if keyword in keywords_found:
      important_keywords.append(keyword)

  return important_keywords[:4]


imp_keywords = get_keywords(text,summarized_text)
print (imp_keywords)

question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')
question_tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_squad_v1')
question_model = question_model.to(device)

def get_question(context,answer,model,tokenizer):
  text = "context: {} answer: {}".format(context,answer)
  encoding = tokenizer.encode_plus(text,max_length=384, pad_to_max_length=False,truncation=True,
                                   return_tensors="pt").to(device)
  input_ids, attention_mask = encoding["input_ids"], encoding["attention_mask"]

  outs = model.generate(input_ids=input_ids,attention_mask=attention_mask,early_stopping=True,
                                  num_beams=5, num_return_sequences=1,no_repeat_ngram_size=2,
                                  max_length=72)


  dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]


  Question = dec[0].replace("question:","")
  Question= Question.strip()
  return Question



for wrp in wrap(summarized_text, 150):
  print (wrp)
print ("\n")

for answer in imp_keywords:
  ques = get_question(summarized_text,answer,question_model,question_tokenizer)
  print (ques)
  print (answer.capitalize())
  print ("\n")